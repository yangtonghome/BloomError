\presec
\section{Experimental Results} \postsec
\label{sec:evaluation}
%In this section, we evalute the 

The goal of this section is to validate the accuracy and correctness of our proposed bound and formula.
In this section, we first validate the formula $f_{bloom}$, and then validate our proposed formula of optimal $k$ -- equation \ref{equ:mykform}.

\presub
\subsection{Experimental Setup} \postsub
In order to evaluate experimentally the FP probability of a set of entries, we wrote a C++ program to generate a large set of unique entries with 20 characters in each. 
%
It takes around 1 hour on an Intel(R) Core(TM) i7-920 with a 4-core computer working at 2.67GHz to generate 100M unique entries and more than 3 hours to get 300M entries which occupy more than 6GB memory. 
%
These two sets are used to evaluate FP probability and optimal values of $k$.
%In place of trying to find hash functions with low complexity we rather use hash functions known to be uniform. For this purpose, we collect 26 hash functions mainly from website \cite{...}, 
We collect 20 hash functions, mainly from \cite{hashfuncssigcommccr}, and the name of hash functions are shown in Table 
\ref{table:hashfunction}. We choose different hash functions for the experiments several times, and the experimental results show little differences and thus we only show the experimental results when using the first $k$ hash functions.

%a set of hashing function based on 26 basic hash functions and we build the needed hash functions from this universal hash function.


%TABLE III
%COLLECTED HASH FUNCTIONS AND THEIR NUMBER IN THIS PAPER
%APHash BKDR BOB CRC32 DEKHash
%h1 h2 h3 h4 h5
%DJBHash FNV32 Hsieh JSHash OCaml
%h6 h7 h8 h9 h10
%OAAT PJWHash RSHash SBOX SDBM
%h11 h12 h13 h14 h15
%Simple SML STL MD5 SHA-1
%h16 h17 h18 h19 h20


\begin{table} [htbp]
\vspace{0in}
\caption{Hash functions used in our experiments.}
\centering
\label{table:hashfunction}
\begin{tabular}{| l | l | l | l | l |}
\hline 1: APHash  & 2: BKDR  & 3: BOB  & 4: CRC32 & 5: DEKHash \\
\hline 6: DJBHash & 7: FNV32 & 8: Hsieh & 9: JSHash & 10: OCaml \\
\hline 11: OAAT & 12: PJWHash & 13: RSHash &14: SBOX &15: SDBM \\
\hline 16: Simple &17: SML & 18: STL & 19: MD5 &20: SHA-1 \\
\hline
\end{tabular}
\end{table}





\presub
\subsection{False Positive Probability Test} \postsub

\begin{table}[htbp]
\vspace{0in}
	\centering\caption{False positive probability in theory and simulation.}
\vspace{0in}
	\begin{tabular}{l l l l l}
		\hline
		k   &	\# of FP	&	FP from $f_{bloom}$	&	FP of simulation	&	Error ratio	(\%)\\
		\hline
		2	&	24814826	&	0.25003480 	&	0.24814830 	&	-0.7545290 	\\
		4	&	6263312	&	0.06250841 	&	0.06263312 	&	0.1995030 	\\
		6	&	1565056	&	0.01562703 	&	0.01565056 	&	0.1505790 	\\
		8	&	392198	&	0.00390674 	&	0.00392198 	&	0.3901310 	\\
		10	&	95314	&	0.00097668 	&	0.00095314 	&	-2.4102060 	\\
		12	&	24946	&	0.00024417 	&	0.00024946 	&	2.1670100 	\\
		14	&	6166	&	0.00006104 	&	0.00006166 	&	1.0125530 	\\
		16	&	1528	&	0.00001526 	&	0.00001528 	&	0.1283920 	\\
		\hline
	\end{tabular}
	\label{table:fp:theory:sim}
\end{table}


\begin{figure*}[htbp]
 	\begin{minipage}{0.28\linewidth}
 		\centerline{\includegraphics[width=6.2cm]{fperrork4}}
 		\centerline{(a) k=4}
 	\end{minipage}
 	\hfill
 	\begin{minipage}{0.28\linewidth}
 		\centerline{\includegraphics[width=5.8cm]{fperrork5}}
 		\centerline{(b) k=5}
 	\end{minipage}
 	\hfill
 	\begin{minipage}{0.28\linewidth}
 		\centerline{\includegraphics[width=5.8cm]{fperrork6}}
 		\centerline{(c) k=6}
 	\end{minipage}
 	\caption{FP probability error ratio vs. \# of queries with different $k$.}  \vspace{0in}
 	\label{fig:error:ratio}
 \end{figure*}

 \begin{figure*}[htbp]
 	\begin{minipage}{0.28\linewidth}
 		\centerline{\includegraphics[width=6.2cm]{FPtheorysimk4}}
 		\centerline{(a) k=4}
 	\end{minipage}
 	\hfill
 	\begin{minipage}{0.28\linewidth}
 		\centerline{\includegraphics[width=5.8cm]{FPtheorysimk5}}
 		\centerline{(b) k=5}
 	\end{minipage}
 	\hfill
 	\begin{minipage}{0.28\linewidth}
 		\centerline{\includegraphics[width=5.8cm]{FPtheorysimk6}}
 		\centerline{(c) k=6}
 	\end{minipage}
 	\caption{FP probability error vs. \# of queries with different $k$.}  \vspace{-0.07in}
 	\label{fig:error:abso}
 \end{figure*}
 
  \begin{figure*}[htbp]
  	\begin{minipage}{0.28\linewidth}
  		\centerline{\includegraphics[width=6.2cm]{NotAcck4}}
  		\centerline{(a) k=4}
  	\end{minipage}
  	\hfill
  	\begin{minipage}{0.28\linewidth}
  		\centerline{\includegraphics[width=5.8cm]{NotAcck5}}
  		\centerline{(b) k=5}
  	\end{minipage}
  	\hfill
  	\begin{minipage}{0.28\linewidth}
  		\centerline{\includegraphics[width=5.8cm]{NotAcck6}}
  		\centerline{(c) k=6}
  	\end{minipage}
  	\caption{FP probability error vs. \# of queries with independent queries.} \vspace{-0.07in}
  	\label{fig:error:notAcc}
  \end{figure*}
 
  
  \begin{figure*}[htbp]
  	\begin{minipage}{0.28\linewidth}
  		\centerline{\includegraphics[width=6.2cm]{m12n8k}}
  		\centerline{(a) n=8,000}
  	\end{minipage}
  	\hfill
  	\begin{minipage}{0.28\linewidth}
  		\centerline{\includegraphics[width=5.8cm]{m12n10k}}
  		\centerline{(b) n=10,000}
  	\end{minipage}
  	\hfill
  	\begin{minipage}{0.28\linewidth}
  		\centerline{\includegraphics[width=5.8cm]{m12n12k}}
  		\centerline{(c) n=12,000}
  	\end{minipage}
  	\caption{Variation of FP probability as a function of the number of hash functions $k$ for $m=100,000$ and different number of inserted entries $n$} \vspace{0in}
  	\label{fig:bestk}
  \end{figure*}
  
  


%ShBFM calculated in Equation (1) using our experimental
%results. Then we compare ShBFM with BF and 1MemBF
%[14], which represents the prior scheme for answering mem-
%bership queries, in terms of FPR, the number of memory
%accesses, and query processing speed.




\subsubsection{Basic Test} \textit{Our experimental results show that the error ratio shows that the experimental results of FP probability follow the predictions of $f_{bloom}$ very well.}
In this experiment, we use the 100M-entries file described above. Each round of experiments is done with a given value of $k$ chosen as an even number from 2 to 16.
We insert the first 5000 ($n$ = 5000) elements into the Standard Bloom Filter (SBF), and then calculate the optimal $m$ according to the formula~\ref{equ:mykform}, and then get:
%\begin{equation}
%\label{formulaM}
%m=\dfrac{k*n}{ln2}
%\end{equation}
\begin{equation}
\label{formulaM}
m=\dfrac{1}{1-2^{-\dfrac{1}{kn}}}
\end{equation}
In order to evaluate the FP probability, we query 100M elements from the BF we built, and the query results are shown in Table \ref{table:fp:theory:sim}.
%
We show experimental results of FP probability of BF as well as the FP probability using the formula of $f_{bloom}$.
%also in the table along with the empirically estimated FP probability the one predicted using the $f_{bloom}$ as well as the error ratio between these two rates.
It can be seen that as $k$ increases from 2 to 16, the number of false positives decreases from 24814826 to 1528 and the error ratio is 2.41\% at most.




 \subsubsection{Error ratio vs. Querying number}

 
  
  
 We build the same SBF as described previously and use the same 100M-traffic file. We run experiments when $k$ is 4, 5, and 6, respectively. $n$ is still 5000, and $m$ is calculated to be the optimal number according to formula \ref{formulaM}. We query 1M up to 100M elements and calculate the error ratio when every next 1M elements are queried.
 %We compute the FP probability using the accumulated sum of the FP number, which also contains the ones counted before. So we can get 100 error ratio spots. That means the $100th$ result of FP number contains all the previous ones.


The results are shown in Figure \ref{fig:error:ratio}. It shows that at the very beginning, the error ratio is much bigger and also with drastic fluctuation. The more elements we query, the stabilizer the error ratio will be.
%It is because when the number of query elements is large, the FP number will be bigger and the results will be more accurate.
When the number of false positives in a test is small, the test results can hardly be reliable. In our test, the smallest number of false positives is 15,820, which is the first spot in Figure \ref{fig:error:ratio}c, when $k$ is 6 and query number is 1M.
All in all, the error ratio is actually so small that it can be ignored. They are ranging from -0.533\% to +0.356\% when $k=4$, ranging from +0.188\% to +0.699\% when $k=5$, and ranging from -0.138\% to +1.235\% when $k=6$.



 To give a more intuitive result, we plot Figure \ref{fig:error:abso}. The blue line is the theoretical FP probability, while the other curve is the evaluated FP probability (defined as FP number/total query number). That error ratio stabilizes with the increase of the querying number still holds.


To give a whole picture, we carry out another experiment. In this experiment, we query the first $n$ elements and sum up the FP number. And then, we pick up the latter $n$ elements and also get the FP number. These two groups of elements are totally different without duplicate elements across the groups. Thus, we query up to $100*n$ elements and get 100 spots. The 100M-element traffic file is not large enough for this experiment, so we use the 300M-element traffic file which contains more than 300M elements we described in the experimental setup section.

As shown in Figure \ref{fig:error:notAcc}, the smallest number of false positives is 1,075, which is still in the first spot in Figure \ref{fig:error:notAcc}c, when $k$ is 6 and this time query number is 68,712. Although it is smaller than the previous accumulated experimental results, it is still bigger than 1,000, so the result is reasonable. By the way, the 100th query number is $100*68712=6,871,200$ and the number of FP is 109,713, which is large enough.

 It can be seen from Figure \ref{fig:error:notAcc}, the error ratios fluctuate drastically at the beginning and quickly converge to a small range. And also, the error ratios are very small ranging from -0.812\% to +1.500\% when $k=4$, ranging from -3.559\% to +1.284\% when $k=5$, and ranging from +0.115\% to +5.581\% when $k=6$.

\presub
\subsection{Optimal $k$ Formula Validation} \postsub


\textit{Our experimental results show that our proposed formula of optimal $k$ is accurate.}
In this experiment, we validate that the formula Eq. \ref{equ:mykform} derived for $k^*$, gives a value minimizing the FP probability. For this purpose, we create large Bloom filters with $m=100,000$ and with different $k$ varying from 2 to 16,  and then insert $n=8000$, $10000$, and $12000$ entries into it, respectively. We use the same 100M-entries to evaluate the FP probability. We show the results in Figure \ref{fig:bestk}. We also show the value of FP probability derive using the formula $f_{bloom}$.


It can be seen in the figure \ref{fig:bestk} for the given value of $m$, $n$, and $k$, the experimental results and the theoretical values of FP probability match well. Moreover, when using formula in Eq. \ref{equ:mykform}, on the third scenario that is $n=12,000$, one can derive an optimal value of $k^*=6$. As shown in Figure \ref{fig:bestk}, it can be seen that this is indeed the value minimizing the FP probability to be 1.816\%. Similar observations are made for $n=8000$ and $10,000$.

% \begin{figure*}[htbp]
 %	\begin{minipage}{0.28\linewidth}
 %		\centerline{\includegraphics[width=6.2cm]{PCQpsk4}}
 %		\centerline{(a) k=4}
 %	\end{minipage}
 %	\hfill
 %	\begin{minipage}{0.28\linewidth}
 %		\centerline{\includegraphics[width=5.8cm]{PCQpsk6}}
 %		\centerline{(b) k=6}
 %	\end{minipage}
 %	\hfill
 %	\begin{minipage}{0.28\linewidth}
 %		\centerline{\includegraphics[width=5.8cm]{PCQpsk8}}
 %		\centerline{(c) k=8}
 %	\end{minipage}
 %	\caption{Query speed (Qps) with different traffic.}
 %	\label{fig:PC:QPS}
 %\end{figure*}

% \begin{figure*}[htbp]
 %	\begin{minipage}{0.28\linewidth}
 %		\centerline{\includegraphics[width=6.2cm]{manyCoreTraffic1}}
 %		\centerline{(a) k=4}
 %	\end{minipage}
 %	\hfill
 %	\begin{minipage}{0.28\linewidth}
 %		\centerline{\includegraphics[width=5.8cm]{manyCoreTraffic2}}
 %		\centerline{(b) k=6}
 %	\end{minipage}
 %	\hfill
 %	\begin{minipage}{0.28\linewidth}
 %		\centerline{\includegraphics[width=5.8cm]{manyCoreTraffic3}}
 %		\centerline{(c) k=8}
 %	\end{minipage}
 %	\caption{Query speed VS. \# of cores.} \vspace{0in}
 %	\label{fig:manycore:QPS}
 %\end{figure*}

It can be seen from Figure \ref{fig:bestk} that the optimal $k$s are totally identical between the theoretical and practical results. For example, when $m=100,000$, $n=12,000$ and the best $k$ should be 5.78 obtained from our formula \ref{equ:mykform}. Since $k$ is an integer, we set $k=6$. In this experiment, when $k$ is 6, the FP probability is the lowest, which is 1.816\% in the 15 spots ranging from 2 to 16. The same logical also applied to other cases when $n$ is 8,000 and 10,000.

%\presub
%\subsection{Performance Test on CPU and Many-core Platform} \postsub

 %To better understand the SBF, we conduct the performance test of SBF on two platforms: CPU and Many-core.

 %\subsubsection{Performance on CPU}

 %We run the program on the same computer described above in the experimental setup section. We set up the SBF with the parameter $n=5000$, $k=4,6,8$ respectively and $m$ to be optimal according to the formula \ref{formulaM}. Then we query 100,000,000 elements in the 100M-traffic file. And for each 1,000,000 queries, we sum up the running time and calculate the query speed. The 100 spots are showed in Figure \ref{fig:PC:QPS}. The average query speed is $13.068Mqps$ (Million queries per second) when $k=4$, $12.496Mqps$ when $k=6$, and $12.326Mqps$ when $k=8$.




 %\subsubsection{Performance on Many-core Platform}

 %We also evaluated the query speed on the SBF versus the number of cores. We carry out experiments on the many-core platform Telera TLR4-03680. The many-core processor has 36 cores with a 256K L2 cache for each one. One L2 cache access needs 9 cycles.

 %In our implementation of the C++ program on many-core platform, we set one core to serve as the main thread and all other 35 cores to be the query threads. Also the main thread is in charge of dividing and distributing 35,000,000 elements (also from the beginning of the 100M traffic file) to 35 groups. Each group has 1,000,000 elements to be queried by one core and each core has its own SBF instance for querying. Of course, the SBF instances in the 35 cores are exactly the same with each other. We set up the SBF with the parameters $n=5000$, $k=4,6,8$ respectively and $m$ to be optimal according to the formula \ref{formulaM}.

 %Our experimental results are showed in Figure \ref{fig:manycore:QPS}. We can see that as the number of cores grows, the query speed increases linearly. Note that because one core is responsible for the main thread, which distributes the elements and collects the results from other cores, we only have the results of 35 cores. And the query speed can achieve $339Mqps$ when $k=4$ and 35 cores are running in parallel.







